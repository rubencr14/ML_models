{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:40px; font-weight:bold; margin:20px; margin-bottom:100px; text-align: justify;text-shadow: 1px 1px 1px #919191,\n",
    "        1px 2px 1px #919191,\n",
    "        1px 3px 1px #919191,\n",
    "        1px 4px 1px #919191,\n",
    "        1px 5px 1px #919191,\n",
    "        1px 6px 1px #919191,\n",
    "        1px 7px 1px #919191,\n",
    "        1px 8px 1px #919191,\n",
    "        1px 9px 1px #919191,\n",
    "        1px 10px 1px #919191,\n",
    "    1px 18px 6px rgba(16,16,16,0.4),\n",
    "    1px 22px 10px rgba(16,16,16,0.2),\n",
    "    1px 25px 35px rgba(16,16,16,0.2),\n",
    "    1px 30px 60px rgba(16,16,16,0.4)\">Long Short Term Memory Recurrent Networks</div>\n",
    "\n",
    "<div style=\"font-style: italic; font-weight: bold; font-size:35px; text-align:center; font-family: Garamond\">by Rubén Cañadas Rodríguez</div>\n",
    "\n",
    "<div style=\"font-size: 30px; margin: 20px; margin-bottom: 40px; margin-left: 0px; line-height: 40pt\">\n",
    "\n",
    "<div style=\"font-size: 30px; font-family: Garamond; font-weight: bold; margin: 30px; margin-left: 0px; margin-bottom: 10px; \">Contents</div>\n",
    "<ol>\n",
    "<li>Introduction</li>\n",
    "<li>Recurrent Neural Networks (RNNs)</li>\n",
    "<li>Long Short Term Memory (LSTM)</li> \n",
    "<li>Text generation</li> \n",
    "<li>Coding</li> \n",
    "</ol>\n",
    "</div>\n",
    "<div style=\"font-size: 30px; font-weight: bold; margin-bottom: 20px; margin-top: 30px\"> Introduction </div>\n",
    "<div style=\"font-size: 30px; font-weight: bold; margin-bottom: 20px; margin-top: 30px\"> Recurrent Neural Networks (RNNs) </div>\n",
    "<div style=\"font-size: 30px; font-weight: bold; margin-bottom: 20px; margin-top: 30px\"> Long Short Term Memory (LSTM) </div>\n",
    "<div style=\"font-size: 30px; font-weight: bold; margin-bottom: 20px; margin-top: 30px\"> Text generation </div>\n",
    "<div style=\"font-size: 30px; font-weight: bold; margin-bottom: 20px; margin-top: 30px\"> Coding </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 40px; font-weight: bold; text-align: left\">Import packages and modules</div>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re #regular expressions for treating text\n",
    "import numpy as np\n",
    "from nltk import word_tokenize #Natural Language Processing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading csv\n",
    "CSV_NAME = \"QUOTE.csv\"\n",
    "df = pd.read_csv(CSV_NAME)\n",
    "quotes = list(df.quote + \"\\n\") #adding a break at the end of each quote!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices char  {'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '/': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, '?': 20, 'A': 21, 'B': 22, 'C': 23, 'D': 24, 'E': 25, 'F': 26, 'G': 27, 'H': 28, 'I': 29, 'J': 30, 'K': 31, 'L': 32, 'M': 33, 'N': 34, 'O': 35, 'P': 36, 'Q': 37, 'R': 38, 'S': 39, 'T': 40, 'U': 41, 'V': 42, 'W': 43, 'X': 44, 'Y': 45, 'Z': 46, 'a': 47, 'b': 48, 'c': 49, 'd': 50, 'e': 51, 'f': 52, 'g': 53, 'h': 54, 'i': 55, 'j': 56, 'k': 57, 'l': 58, 'm': 59, 'n': 60, 'o': 61, 'p': 62, 'q': 63, 'r': 64, 's': 65, 't': 66, 'u': 67, 'v': 68, 'w': 69, 'x': 70, 'y': 71, 'z': 72}\n"
     ]
    }
   ],
   "source": [
    "removed_char = ['#', '$', '%', '(', ')', '=', ';' ,':',  '*', '+', '£' , '—','’'] #Characters that we dont want to\n",
    "#include in our model and we just remove them!\n",
    "quotes_cleaned = []\n",
    "\n",
    "for quote in quotes: \n",
    "    # remove unused character\n",
    "    for s_char in removed_char:\n",
    "        quote = quote.replace(s_char, ' ')\n",
    "    \n",
    "    # remove white space\n",
    "    pattern = re.compile(r'\\s{2,}') #regular expression for replacing more than two white spaces\n",
    "    quote = re.sub(pattern, ' ', quote)\n",
    "\n",
    "    quotes_cleaned.append(quote)\n",
    "\n",
    "text = ' '.join(quotes_cleaned)\n",
    "chars = sorted(list(set(text))) #Chars are a list of characters found in the quotes (letters + symbols)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars)) #To each character we assign a number\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars)) #The contrary, to each number we asssign a character\n",
    "print(\"indices char \", char_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If you live to ',\n",
       " ' live to be a h',\n",
       " 'to be a hundred',\n",
       " 'a hundred, I wa',\n",
       " 'red, I want to ',\n",
       " ' want to live t',\n",
       " 'to live to be a',\n",
       " 'e to be a hundr',\n",
       " 'e a hundred min',\n",
       " 'ndred minus one',\n",
       " 'minus one day s',\n",
       " 'one day so I ne',\n",
       " 'y so I never ha',\n",
       " ' never have to ',\n",
       " ' have to live w',\n",
       " 'to live without',\n",
       " 'e without you.\\n',\n",
       " \"Promise me you'\",\n",
       " \"e me you'll alw\",\n",
       " \"ou'll always re\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "maxlen = 15 # Lenght of the new sentences\n",
    "step = 6\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for quote in quotes_cleaned:\n",
    "    for i in range(0, len(quote) - maxlen, step):\n",
    "        sentences.append(quote[i: i + maxlen])\n",
    "        next_chars.append(quote[i + maxlen])\n",
    "    sentences.append(quote[-maxlen:])\n",
    "    next_chars.append(quote[-1])\n",
    "sentences = sentences[:100]\n",
    "sentences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; margin: 20px; margin-left:-300px\">\n",
    "  <tr>\n",
    "    <th>Predictors (X train)</th>\n",
    "    <th>Labels (Y train)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>they</td>\n",
    "    <td>are</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>they are</td>\n",
    "    <td>learning</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>they are learning</td>\n",
    "    <td>artificial</td>\n",
    "  </tr>\n",
    "      <tr>\n",
    "    <td>they are learning artificial</td>\n",
    "    <td>inteligence</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
